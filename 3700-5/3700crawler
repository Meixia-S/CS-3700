#!/usr/bin/env -S python3 -u

import concurrent
import argparse
import socket
import ssl
import sys
import re

from threading import Lock
from concurrent.futures import ThreadPoolExecutor

DEFAULT_SERVER = "proj5.3700.network"
DEFAULT_PORT = 443


class Crawler:
    """
    This is the Crawler class that describes a web crawler. It is responsible for traversing the Fakebook site by first
    logging into it for a particular user. It traverses through all the pages in the Fakebook site to ultimately find
    5 secret_flags (per user) and print them out.
    """
    flags = []
    profiles_to_inspect = []
    profiles_already_added = []

    token = ""
    session_id = ""
    middlewaretoken = ""

    def __init__(self, args):
        self.server = args.server
        self.port = args.port
        self.username = args.username
        self.password = args.password

    def run(self):
        """
        The primary method that logins into the server with the given credentials, navigates to the fakebook page and
        then traverses through all the profiles and their list of friends in a BFS manner. It first collects all the
        href values that contain /fakebook/ in it and then looks for the hidden secret flags. The program ends when it
        is able to print out the 5 secret flags to STDOUT and closes the connection.

        :return: N/A
        """
        lock = Lock()
        with ThreadPoolExecutor(5) as executor:
            thread1 = executor.submit(self.traversing_profiles, lock)
            thread2 = executor.submit(self.traversing_profiles, lock)
            thread3 = executor.submit(self.traversing_profiles, lock)
            thread4 = executor.submit(self.traversing_profiles, lock)
            thread5 = executor.submit(self.traversing_profiles, lock)

            concurrent.futures.wait([thread1, thread2, thread3, thread4, thread5])

# Traversing Though Pages ----------------------------------------------------------------------------------------------
    def traversing_profiles(self, lock):
        """

        :param lock:
        :return:
        """
        ssl_default_context_new = ssl.create_default_context()
        mysocket = ssl_default_context_new.wrap_socket(
            socket.socket(socket.AF_INET, socket.SOCK_STREAM),
            server_hostname=self.server)
        mysocket.connect((self.server, self.port))

        fakebook_html_page = self.login(mysocket)
        self.page_inspection(fakebook_html_page, lock)

        while len(self.flags) < 5:
            with lock:
                current_profile = self.profiles_to_inspect.pop(0)
            first_profile_request = self.create_get_request(current_profile)
            first_profile_request_response = self.handle_sending_and_receiving(first_profile_request, mysocket)
            self.page_inspection(first_profile_request_response, lock)

            if self.has_friends(first_profile_request_response):
                self.traversing_friends_list(current_profile, lock, mysocket)
            else:
                continue

        mysocket.close()

    def traversing_friends_list(self, current_profile, lock, mysocket):
        """

        :param current_profile:
        :param lock:
        :param mysocket:
        :return:
        """
        # gets to the first list of friends
        first_friend_page = self.create_get_request(current_profile + "friends/1/")
        first_friend_page_response = self.handle_sending_and_receiving(first_friend_page, mysocket)
        self.page_inspection(first_friend_page_response, lock)
        page_num = self.get_page_nums(first_friend_page_response)

        counter = 2

        for i in range(page_num - 1):
            # goes through the rest of the pages of friends
            next_page_request = self.create_get_request(current_profile + "friends/" + str(counter) + "/")
            next_page_request_response = self.handle_sending_and_receiving(next_page_request, mysocket)
            self.page_inspection(next_page_request_response, lock)

            counter += 1

    def create_get_request(self, current_url):
        """ Creates a new GET request with the given url.

        :param current_url: the url to the page we want to retrieve
        :return: the completed GET request
        """
        request = 'GET ' + current_url + ' HTTP/1.1\r\n'
        request += 'Host: www.3700.network\r\n'
        request += 'Content-Length: 0\r\n'
        request += 'Cookie: sessionid=' + self.session_id + '\r\n'
        request += 'Connection: keep-alive\r\n\r\n'

        return request

    def page_inspection(self, page_html, lock):
        """
        Traverses over the given html of a page to look for...
            - the secret flags and add them to the flag array if any are found
            - href (starting with "/fakebook/") values that are to profiles and add all to the profiles_to_inspect queue

        :param page_html: the page in html format
        :return: N/A
        """
        find_flags = re.findall(r"FLAG: \S+<", page_html.decode('ascii'))
        for i in range(len(find_flags)):
            flag_value_with_tag = find_flags[i]
            flag_value = flag_value_with_tag[6:len(flag_value_with_tag) - 1]
            self.flags.append(flag_value)
            print(flag_value)

        if len(self.flags) == 5:
            return

        find_urls = re.findall(r"href=\S+>", page_html.decode('ascii'))
        for i in range(len(find_urls)):
            if 'href="/fakebook/' in find_urls[i] and "/friends/" not in find_urls[i]:
                url_with_string = find_urls[i]
                url = url_with_string[6:len(url_with_string) - 2]
                with lock:
                    if url not in self.profiles_already_added:
                        self.profiles_already_added.append(url)
                        self.profiles_to_inspect.append(url)

    def has_friends(self, page_html):
        """ Determines whether-or-not a given profile page has a friends page/url.

        :param page_html: the profile page in html format
        :return: True is the given profile page has a friend link and False if it does not
        """
        friends = re.findall(r"/friends/1/", page_html.decode('ascii'))

        if len(friends) > 0:
            return True
        return False

    def get_page_nums(self, page_html):
        """ Retrieves the number of pages that are in a given friends/1/ page of a person's profile.

        :param page_html: the first page of friends in a person's profile.
        :return: the number of pages
        """
        page_nums = re.findall(r"Page \d of \d", page_html.decode('ascii'))
        page_num = page_nums[0]
        return int(page_num[len(page_num) - 1:len(page_num)])

# Handling Sending and Receiving ---------------------------------------------------------------------------------------
    def make_new_connection(self, mysocket):
        """ Closes the mysocket connection and creates a new one using the same server and port values.

        :return: N/A
        """
        mysocket.close()
        ssl_default_context_new = ssl.create_default_context()
        mysocket = ssl_default_context_new.wrap_socket(
            socket.socket(socket.AF_INET, socket.SOCK_STREAM),
            server_hostname=self.server)
        return mysocket

    def handle_sending_and_receiving(self, request_website, mysocket):
        """
        Sends the given request and receives the data from the server. It does this by ensuring the entire length of the
        data is being received and by handling the different error types.

        :param request_website: the request that is sent to the server
        :return: the response sent back by the server
        """
        self.handle_sending(request_website.encode('ascii'), mysocket)

        while True:
            get_data, mysocket = self.handle_receiving(mysocket)
            get_data_as_string = get_data.decode('ascii')

            if "200 OK" not in get_data_as_string:
                new_request = self.handle_errors(get_data_as_string, request_website)
                if "403 Forbidden" in get_data_as_string or "404 Not Found" in get_data_as_string:
                    self.middlewaretoken, self.token, self.session_id = self.retrieve_cookies(get_data)
                    new_request = self.create_get_request(self.profiles_to_inspect.pop(0))

                if new_request is None:
                    self.handle_sending(request_website.encode('ascii'), mysocket)
                else:
                    self.handle_sending(new_request.encode('ascii'), mysocket)
            else:
                return get_data

    def handle_sending(self, website, mysocket):
        """

        :param website:
        :param mysocket:
        :return:
        """
        try:
            mysocket.send(website)
        except socket.error:
            mysocket = self.make_new_connection(mysocket)
            mysocket.connect((self.server, self.port))
            mysocket.send(website)

    def handle_receiving(self, mysocket):
        """ This receives the response from the socket in chunks to ensure the entire response is received.
        Exits on an OSError, TypeError, or ValueError.

        :return: This returns the entire response received from the socket.
        """
        response_chunks = []
        while True:
            try:
                response_chunk = mysocket.recv(4096)
                response_chunks.append(response_chunk)
                response = b''.join(response_chunks)
            except OSError:
                sys.exit()
            except TypeError:
                sys.exit()
            except ValueError:
                sys.exit()

            if bytes('</html>', 'ascii') in response or bytes('content-length: 0', 'ascii') in response or response == b'':
                break

        if bytes('connection: close', 'ascii') in response or response == b'':
            mysocket = self.make_new_connection(mysocket)
            mysocket.connect((self.server, self.port))

        return response, mysocket

    def handle_errors(self, data_response, request):
        """ This handles the possible errors ("302 Found", "403 Forbidden", "404 Not Found", or
        "503 Service Unavailable") seen in a given HTTP response and reforms a given HTTP request as necessary.

        :param data_response: This is the HTTP response to parse for determining the type of error that has occurred.
        :param request: This is the HTTP request associated with data_response, that may need to be reformatted.
        :return: This returns the reformatted request based on the type of error that occurred.
        """
        if "302 Found" in data_response:
            locations_redirect = re.findall(r"location: \S+", data_response)

            if locations_redirect[0] != "":
                location_redirect = locations_redirect[0]
                new_url = location_redirect[9:]
                self.middlewaretoken, self.token, self.session_id = self.retrieve_cookies(data_response.encode('ascii'))
                new_request = self.create_get_request(new_url)
                return new_request
        elif "403 Forbidden" in data_response or "404 Not Found" in data_response:
            return "403 Forbidden or 404 Not Found"
        elif "503 Service Unavailable" in data_response:
            return request

# Login in -------------------------------------------------------------------------------------------------------------
    def login(self, mysocket):
        """
        This initiates the login into Fakebook via a GET request access the login page, then a POST request to login
        with the proper username and password, and then gets the initial page (/fakebook/) that can be accessed
        after logging in. It continuously updates the csrfmiddlewaretoken, csrftoken, and sessionid.

        :return: This returns the initial page (/fakebook/) as bytes.
        """
        request_website = "GET /accounts/login/ HTTP/1.1\r\n"
        request_website += "Host: www.3700.network\r\n"
        request_website += "Connection: keep-alive\r\n\r\n"
        get_data = self.handle_sending_and_receiving(request_website, mysocket)

        self.middlewaretoken, self.token, self.session_id = self.retrieve_cookies(get_data)
        post_request = self.create_post_request("/accounts/login/")
        post_data = self.handle_sending_and_receiving(post_request, mysocket)

        self.middlewaretoken, self.token, self.session_id = self.retrieve_cookies(post_data)
        get_fakebook_request = self.create_get_request("/fakebook/")
        get_fakebook_data = self.handle_sending_and_receiving(get_fakebook_request, mysocket)

        return get_fakebook_data

    def retrieve_cookies(self, response):
        """ This retrieves the csrftoken, sessionid, and/or csrfmiddlewaretoken from a given HTTP response.

        :param response: This is the HTTP response to be parsed to retrieve the csrftoken, sessionid, and
              csrfmiddlewaretoken.
        :return: This returns the csrftoken, sessionid, and csrfmiddlewaretoken from a given HTTP response. If one of
                these values is not found in the response, the previous value (stored in a global variable) is returned.
        """
        middlewaretoken, token, session = self.middlewaretoken, self.token, self.session_id

        sessions = re.findall(r"sessionid=\S+;", response.decode('ascii'))
        if len(sessions) == 1:
            session = sessions[0][10:len(sessions[0]) - 1]

        tokens = re.findall(r"csrftoken=\S+;", response.decode('ascii'))
        if len(tokens) == 1:
            token = tokens[0][10:len(tokens[0]) - 1]

        middlewaretokens = re.findall(r"value=\S+>", response.decode('ascii'))
        if len(middlewaretokens) == 1:
            middlewaretoken = middlewaretokens[0][7:len(middlewaretokens[0]) - 2]

        return middlewaretoken, token, session

    def create_post_request(self, url):
        """
        This creates a POST request to be able to login to website with the given url. It sends the username, password,
        and csrfmiddlewaretoken in the body of the request. It also sends Host, Content-Type, Content-Length, and Cookie.
        :param url: This is the URL to send the POST request to.
        :return: This returns the formed POST request.
        """
        payload = ("username=" + self.username + "&password=" + self.password +
                   "&csrfmiddlewaretoken=" + self.middlewaretoken)
        content_length = len(payload)
        request = "POST " + url + " HTTP/1.1\r\n"
        request += "Host: www.3700.network\r\n"
        request += "Content-Type: application/x-www-form-urlencoded\r\n"
        request += "Content-Length: " + str(content_length) + "\r\n"
        request += "Cookie: csrftoken=" + self.token + "; sessionid=" + self.session_id + "\r\n"
        request += "Connection: keep-alive\r\n\r\n"
        request += payload

        return request


if __name__ == "__main__":
    # This is the main method that parses the command line input to retrieve the server, port, username, and password
    # information, so Fakebook can be properly crawled.
    parser = argparse.ArgumentParser(description='crawl Fakebook')
    parser.add_argument('-s', dest="server", type=str, default=DEFAULT_SERVER, help="The server to crawl")
    parser.add_argument('-p', dest="port", type=int, default=DEFAULT_PORT, help="The port to use")
    parser.add_argument('username', type=str, help="The username to use")
    parser.add_argument('password', type=str, help="The password to use")
    args = parser.parse_args()
    sender = Crawler(args)
    sender.run()
